{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f92dcb1",
      "metadata": {
        "id": "5f92dcb1",
        "outputId": "bb819e29-9250-442f-a497-aa7edee69617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tatas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load sample data\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an MLP classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, ),        # Number of hidden layers and units per layer\n",
        "                    activation='relu',                 # Activation function ('identity', 'logistic', 'tanh', 'relu')\n",
        "                    solver='adam',                     # Solver for weight optimization ('lbfgs', 'sgd', 'adam')\n",
        "                    alpha=0.0001,                      # L2 penalty (regularization term) parameter\n",
        "                    batch_size='auto',                 # Size of minibatches for stochastic optimizers\n",
        "                    learning_rate='constant',          # Learning rate schedule ('constant', 'invscaling', 'adaptive')\n",
        "                    learning_rate_init=0.001,          # The initial learning rate\n",
        "                    power_t=0.5,                       # The exponent for inverse scaling learning rate\n",
        "                    max_iter=200,                      # Maximum number of iterations\n",
        "                    shuffle=True,                      # Whether to shuffle samples in each iteration\n",
        "                    random_state=None,                 # Seed for the random number generator\n",
        "                    tol=0.0001,                        # Tolerance for the optimization\n",
        "                    verbose=False,                     # Whether to print progress messages\n",
        "                    warm_start=False,                  # Reuse the previous solution\n",
        "                    momentum=0.9,                      # Momentum for gradient descent update\n",
        "                    nesterovs_momentum=True,           # Whether to use Nesterov's momentum\n",
        "                    early_stopping=False,              # Terminate training when validation score is not improving\n",
        "                    validation_fraction=0.1,           # Proportion of training data to set aside as validation set\n",
        "                    beta_1=0.9,                        # Exponential decay rate for estimates of first moment vector in adam\n",
        "                    beta_2=0.999,                      # Exponential decay rate for estimates of second moment vector in adam\n",
        "                    epsilon=1e-8,                      # Value for numerical stability in adam\n",
        "                    n_iter_no_change=10,               # Maximum number of epochs without any improvement in the loss\n",
        "                    max_fun=15000)                     # Maximum number of function calls for the solver\n",
        "\n",
        "# Train the MLP classifier\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d76c0c",
      "metadata": {
        "id": "62d76c0c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}